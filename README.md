\# OmniCritic-R1



æœ¬é¡¹ç›®åŒ…å« OmniCritic-R1 çš„å®Œæ•´ä»£ç ä¸Žæ•°æ®ï¼Œç”¨äºŽå¤çŽ°è®ºæ–‡ä¸­çš„å¤šæ¨¡æ€å¥–åŠ±æ¨¡åž‹è®­ç»ƒä¸Žè¯„ä¼°æµç¨‹ã€‚



\## ðŸ”§ çŽ¯å¢ƒå‡†å¤‡



å»ºè®®ä½¿ç”¨ä»¥ä¸‹çŽ¯å¢ƒé…ç½®ï¼š



\- Python >= 3.10

\- CUDA >= 11.8

\- æŽ¨èä½¿ç”¨ Linux + å¤šå¡ GPU



\## 1. åˆ›å»ºå¹¶æ¿€æ´»çŽ¯å¢ƒã€ä¸‹è½½ä¾èµ–å’Œæ¨¡åž‹ï¼š



conda create -n omnicritic python=3.10 -y

conda activate omnicritic

pip install -r requirements.txt

cd omniR1-sft-master/ms-swift-main

pip install -e .





ä¸‹è½½qwen2.5omni3bå’Œ7b

ä»¥3bä¸ºä¾‹

from modelscope.hub.snapshot\_download import snapshot\_download



model\_dir = snapshot\_download(

&nbsp;   'qwen/Qwen2.5-Omni-3B',

&nbsp;   cache\_dir='./Qwen2.5-Omni-3B',  # âœ… å¯æŒ‡å®šæœ¬åœ°è·¯å¾„

&nbsp;   revision='master'

)





\##2. å…‹éš†æœ¬é¡¹ç›®

åœ¨ä½ å¸Œæœ›å­˜æ”¾çš„è·¯å¾„ä¸‹æ‰§è¡Œï¼š

git clone https://github.com/tmfk418/omni.git

cd omni



\##3. æ•°æ®å‡†å¤‡



éœ€è¦ä¸‹è½½çš„æ•°æ®é›†æ‰˜ç®¡åœ¨ Hugging Face ä¸Šã€‚å¯ä»¥ä½¿ç”¨ huggingface\_hub åº“è¿›è¡Œä¸‹è½½ã€‚



å®‰è£… huggingface\_hub åº“ï¼š



pip install huggingface\_hub



ä¸‹è½½æ•°æ®é›†ï¼š



from huggingface\_hub import hf\_hub\_download



ä¸‹è½½éŸ³é¢‘ã€è§†é¢‘å’Œå›¾åƒæ•°æ®é›†



image\_dataset = hf\_hub\_download("TMFK/omnir1-dataset", "rlaif-v-dataset.tar.gz")



video\_dataset = hf\_hub\_download("TMFK/omnir1-dataset", "C:\\Users\\tmfk1\\video\\video.zip")



audio\_dataset = hf\_hub\_download("TMFK/omnir1-dataset", "Clotho-AQA dataset.zip")



\##4.æ›´æ–°sftå’Œrlçš„æ•°æ®é›†è·¯å¾„

è¿è¡Œä»¥ä¸‹è„šæœ¬æ¥æ›´æ–°éŸ³é¢‘å’Œè§†é¢‘è·¯å¾„ï¼š



æ›´æ–°è·¯å¾„



python configs/change\_path.py



ç¡®ä¿è·¯å¾„ä¸Žæ‚¨ä¸‹è½½çš„æ–‡ä»¶ç›¸åŒ¹é…ã€‚è„šæœ¬ä¼šæ ¹æ®æŒ‡å®šçš„åŸºç¡€è·¯å¾„æ›´æ–° JSONL æ–‡ä»¶ä¸­çš„sftå’Œrlå›¾åƒã€éŸ³é¢‘å’Œè§†é¢‘è·¯å¾„ã€‚

è¾›è‹¦è½¬æ¢åŽçœ‹ä¸€ä¸‹æ˜¯ä¸æ˜¯å’Œå®žé™…çš„æ•°æ®é›†çš„è·¯å¾„ç›¸ç¬¦



\##5. è¿è¡Œsftä»£ç 

bash scripts/sft\_3b.sh

bash scripts/sft\_3b\_lora.sh

bash scripts/sft\_7b.sh

bash scripts/sft\_7b\_lora.sh



æ³¨æ„ä¿®æ”¹é‡Œé¢çš„æ‰€æœ‰è·¯å¾„

ä»¥sft\_3b.shä¸ºä¾‹
 âœ… æ ¹æ®å®žé™…æ˜¾å¡æ•°å’Œèµ„æºé…ç½®ä¿®æ”¹

export CUDA\_VISIBLE\_DEVICES=0,1,2,3        # â† âœ… è‹¥ç”¨å•å¡æˆ–ä¸åŒç¼–å·éœ€ä¿®æ”¹

âœ… å¯é€‰é¡¹ï¼Œæ ¹æ®ä»»åŠ¡éœ€è¦è®¾ç½®ï¼ˆå›¾åƒ/è§†é¢‘/éŸ³é¢‘ï¼‰

export MAX\_PIXELS=262144

export FPS=1

export FPS\_MAX\_FRAMES=20

export VIDEO\_MAX\_PIXELS=32768

export AUDIO\_MEMMAP=true

export AUDIO\_CHUNK\_SIZE=4000

export AUDIO\_NUM\_WORKERS=4

export VIDEO\_READER\_BACKEND=torchvision

export TOKENIZERS\_PARALLELISM=false

export OMP\_NUM\_THREADS=1

export SWIFT\_DEVICE\_MAP=auto

âœ… å¯åŠ¨è®­ç»ƒä¸»å‘½ä»¤ï¼ˆæ ¹æ®æ¨¡åž‹ã€è·¯å¾„ä¿®æ”¹ï¼‰

torchrun --nproc\_per\_node=4 \\                        # â† âœ… æ”¹ä¸ºä½ çš„æ˜¾å¡æ•°ï¼ˆå¦‚ 1ã€2ã€4ã€8ï¼‰

&nbsp; /data/yiwei.ru/omniR1-sft-master/ms-swift-main/swift/cli/sft.py \\



&nbsp; --do\_train \\



&nbsp; # âœ… æ¨¡åž‹è·¯å¾„ï¼šä¿®æ”¹ä¸ºä½ æœ¬åœ°/è¿œç¨‹çš„åŸºåº§æ¨¡åž‹è·¯å¾„

&nbsp; --model /data/yiwei.ru/modelscope/Qwen/Qwen2.5-Omni-3B \\        # â† âœ… æ›¿æ¢ä¸ºä½ ä½¿ç”¨çš„æ¨¡åž‹è·¯å¾„



&nbsp; # âœ… æ•°æ®é›†è·¯å¾„ï¼šä½¿ç”¨ä½ å‡†å¤‡çš„æ•°æ®é›†ï¼ˆå»ºè®®ç»å¯¹è·¯å¾„ï¼‰

&nbsp; --dataset \\

&nbsp;   /data/yiwei.ru/omniR1-sft-master/OmniCritic/sft\_dataset/audio/final\_sft\_data.jsonl \\

&nbsp;   /data/yiwei.ru/omniR1-sft-master/OmniCritic/sft\_dataset/video/final\_sft\_data.jsonl \\

&nbsp;   /data/yiwei.ru/omniR1-sft-master/OmniCritic/sft\_dataset/image/final\_sft\_data.jsonl \\     # â† âœ… æ›¿æ¢ä¸ºä½ å‡†å¤‡çš„ jsonl æ–‡ä»¶



&nbsp; --train\_type full \\                     



&nbsp; # âœ… è¾“å‡ºè·¯å¾„ï¼šè®­ç»ƒç»“æžœä¼šä¿å­˜åœ¨è¿™é‡Œ

&nbsp; --output\_dir /data/yiwei.ru/omniR1-sft-master/OmniCritic/outputs \\   # â† âœ… æ ¹æ®ä½ æƒ³ä¿å­˜çš„ä½ç½®ä¿®æ”¹



&nbsp; # âœ… è®­ç»ƒå‚æ•°ï¼ˆè¾›è‹¦æ ¹æ®å®žé™…æƒ…å†µè°ƒæ•´ï¼‰

&nbsp; --num\_train\_epochs 2 \\

&nbsp; --per\_device\_train\_batch\_size 1 \\

&nbsp; --per\_device\_eval\_batch\_size 1 \\

&nbsp; --gradient\_accumulation\_steps 12 \\

&nbsp; --learning\_rate 5e-6 \\

&nbsp; --warmup\_ratio 0.03 \\

&nbsp; --max\_length 3072 \\

&nbsp; --eval\_steps 100 \\

&nbsp; --save\_steps 100 \\

&nbsp; --save\_total\_limit 4 \\

&nbsp; --logging\_steps 5 \\

&nbsp; --dataloader\_num\_workers 2 \\

&nbsp; --torch\_dtype bfloat16 \\               

&nbsp; --deepspeed zero2 \\



&nbsp; # âœ… è¾“å‡ºæ—¥å¿—ï¼ˆå»ºè®®ä¿®æ”¹è·¯å¾„ï¼‰

&nbsp; 2>\&1 | tee /data/yiwei.ru/omniR1-sft-master/OmniCritic/logs/log\_file\_3b.txt   # â† âœ… å¯æ›¿æ¢ä¸ºä½ æœ¬åœ°çš„ logs è·¯å¾„



\##6.è¿è¡Œgrpoä»£ç 



bash scripts/grpo\_3b.sh

bash scripts/grpo\_7b.sh



export MAX\_PIXELS=262144                     

export VIDEO\_MAX\_PIXELS=65536                

export NPROC\_PER\_NODE=4                       # âœ… ä½¿ç”¨ GPU æ•°é‡ï¼ˆå¿…é¡»ä¸Ž CUDA\_VISIBLE\_DEVICES æ•°é‡ä¸€è‡´ï¼‰

export CUDA\_VISIBLE\_DEVICES=0,1,2,3           # âœ… è®¾ç½®å®žé™…å¯ç”¨æ˜¾å¡ç¼–å·

export FPS=1

export FPS\_MAX\_FRAMES=20

export AUDIO\_MEMMAP=true

export AUDIO\_CHUNK\_SIZE=4000

export AUDIO\_NUM\_WORKERS=4



swift rlhf \\

&nbsp; --rlhf\_type grpo \\



&nbsp; # âœ… æ¨¡åž‹è·¯å¾„ï¼ˆæ›¿æ¢ä¸ºä½ è‡ªå·±çš„é¢„è®­ç»ƒæ¨¡åž‹ï¼Œå¦‚ 3B æˆ– 7Bï¼‰

&nbsp; --model /data/yiwei.ru/modelscope/Qwen/Qwen2.5-Omni-3B \\

&nbsp; --reward\_funcs mm\_format mm\_content mm\_rubric \\

&nbsp; --reward\_weights 0.4 0.4 0.2 \\

&nbsp; --train\_type lora \\

&nbsp; --lora\_rank 8 \\

&nbsp; --lora\_alpha 32 \\

&nbsp; --target\_modules all-linear \\

&nbsp; --torch\_dtype bfloat16 \\                    

&nbsp; # âœ… å¤šæ¨¡æ€ RL æ•°æ®è·¯å¾„ï¼ˆæ›¿æ¢ä¸ºä½ å‡†å¤‡çš„ jsonl æ–‡ä»¶ï¼‰

&nbsp; --dataset \\

&nbsp;     /data/.../audio/final\_final\_rl\_data.jsonl \\

&nbsp;     /data/.../video/final\_final\_rl\_data.jsonl \\

&nbsp;     /data/.../image/final\_final\_rl\_data.jsonl \\



&nbsp; # âœ… å¤–éƒ¨æ’ä»¶ï¼šè‡ªå®šä¹‰å¥–åŠ±å‡½æ•° / æ•°æ®è§£æžï¼ˆå·²ç»æ”¾åœ¨msâ€”swift-mainçš„é‡Œé¢äº†ï¼Œåªæ”¹è·¯å¾„å‰ç¼€å°±å¥½ï¼‰

&nbsp; --external\_plugins /path/to/new\_plugin.py \\



&nbsp; # æ¨¡åž‹ç”Ÿæˆä¸Žè®­ç»ƒå‚æ•°

&nbsp; --max\_completion\_length 2048 \\

&nbsp; --num\_train\_epochs 1 \\

&nbsp; --per\_device\_train\_batch\_size 1 \\

&nbsp; --per\_device\_eval\_batch\_size 1 \\

&nbsp; --gradient\_accumulation\_steps 4 \\

&nbsp; --learning\_rate 1e-5 \\

&nbsp; --eval\_steps 100 \\

&nbsp; --save\_steps 100 \\

&nbsp; --save\_total\_limit 2 \\

&nbsp; --logging\_steps 5 \\

&nbsp; --max\_length 8192 \\



&nbsp; # âœ… è¾“å‡ºè·¯å¾„ï¼ˆä¿å­˜è®­ç»ƒ checkpointï¼‰ï¼ˆè·¯å¾„éœ€æ”¹ï¼‰

&nbsp; --output\_dir /path/to/outputs/grpo \\



&nbsp; --warmup\_ratio 0.05 \\

&nbsp; --dataloader\_num\_workers 4 \\

&nbsp; --dataset\_num\_proc 4 \\

&nbsp; --num\_generations 4 \\

&nbsp; --temperature 1.0 \\

&nbsp; --top\_p 0.99 \\

&nbsp; --top\_k 50 \\

&nbsp; --lazy\_tokenize false \\

&nbsp; --system /path/to/prompt.txt \\

&nbsp; --deepspeed zero2 \\



&nbsp; --log\_completions true \\



&nbsp; # âœ… ä¿å­˜å®Œæ•´è®­ç»ƒæ—¥å¿—ï¼ˆéœ€æ”¹è·¯å¾„ï¼‰

&nbsp; 2>\&1 | tee /path/to/logs/log\_file\_grpo\_3b.txt

